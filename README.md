# üåé Maya Translator Agent

Agente de traducci√≥n a lenguas ind√≠genas mexicanas usando OpenAI Realtime API. Implementa Speech-to-Speech translation con soporte para m√∫ltiples lenguas ancestrales.

## üéØ Caracter√≠sticas

- ‚úÖ **Speech-to-Speech en tiempo real** con OpenAI Realtime API
- ‚úÖ **8 lenguas ind√≠genas** soportadas (Maya, N√°huatl, Zapoteco, etc.)
- ‚úÖ **Contexto de tr√°mites gubernamentales** para respuestas precisas
- ‚úÖ **WebSocket API** para conexi√≥n desde Swift/iOS
- ‚úÖ **REST API** para traducci√≥n de texto
- ‚úÖ **Serverless** en Vercel con cold start optimizado

## üó£Ô∏è Lenguas Soportadas

| Lengua | Hablantes | Regiones | Familia |
|--------|-----------|----------|---------|
| Maya Yucateco | 800,000 | Yucat√°n, Q. Roo, Campeche | Maya |
| N√°huatl | 1,700,000 | Puebla, Veracruz, Hidalgo | Uto-azteca |
| Zapoteco | 500,000 | Oaxaca | Otomangue |
| Mixteco | 500,000 | Oaxaca, Guerrero, Puebla | Otomangue |
| Otom√≠ | 290,000 | Hidalgo, Edo. M√©xico | Otopame |
| Tzeltal | 470,000 | Chiapas | Maya |
| Totonaco | 250,000 | Veracruz, Puebla | Totonacana |
| Mazateco | 220,000 | Oaxaca | Otomangue |

## üöÄ Inicio R√°pido

### 1. Instalaci√≥n

```bash
# Clonar repositorio
git clone https://github.com/tu-usuario/maya-translator-agent.git
cd maya-translator-agent

# Instalar dependencias
npm install

# Configurar variables de entorno
cp .env.example .env
# Editar .env y agregar tu OPENAI_API_KEY
```

### 2. Desarrollo Local

```bash
# Modo desarrollo con hot-reload
npm run dev

# El servidor estar√° disponible en:
# http://localhost:3000
```

### 3. Deployment a Vercel

```bash
# Instalar Vercel CLI
npm i -g vercel

# Login
vercel login

# Deploy
vercel --prod

# Configurar variable de entorno en Vercel
vercel env add OPENAI_API_KEY
```

## üì° API Reference

### REST Endpoints

#### `GET /health`
Health check del servidor.

```bash
curl http://localhost:3000/health
```

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2025-11-04T10:30:00.000Z",
  "service": "Maya Translator Agent",
  "version": "1.0.0"
}
```

---

#### `GET /api/languages`
Obtener todas las lenguas disponibles.

```bash
curl http://localhost:3000/api/languages
```

**Response:**
```json
{
  "success": true,
  "data": [
    {
      "id": "maya",
      "name": "Maya Yucateco",
      "nameNative": "Maaya t'aan",
      "flag": "üá≤üáΩ",
      "speakers": "800,000",
      "regions": ["Yucat√°n", "Quintana Roo", "Campeche"],
      "family": "Maya"
    }
  ]
}
```

---

#### `POST /api/session`
Crear una sesi√≥n de Realtime API.

```bash
curl -X POST http://localhost:3000/api/session \
  -H "Content-Type: application/json" \
  -d '{
    "language": "maya"
  }'
```

**Response:**
```json
{
  "success": true,
  "data": {
    "sessionId": "sess_abc123...",
    "wsUrl": "wss://api.openai.com/v1/realtime?session_id=sess_abc123...",
    "language": "maya",
    "expiresAt": "2025-11-04T11:00:00Z"
  }
}
```

---

#### `POST /api/translate`
Traducir texto (modo chained como fallback).

```bash
curl -X POST http://localhost:3000/api/translate \
  -H "Content-Type: application/json" \
  -d '{
    "text": "¬øC√≥mo obtengo mi acta de nacimiento?",
    "language": "maya",
    "includesTramitesContext": true
  }'
```

**Response:**
```json
{
  "success": true,
  "data": {
    "original": "¬øC√≥mo obtengo mi acta de nacimiento?",
    "translation": "Bix in k'amik in ts√≠ib siibal?",
    "language": "maya"
  }
}
```

### WebSocket API

#### Conexi√≥n
```javascript
const ws = new WebSocket('ws://localhost:3000/realtime');
```

#### Protocolo de Mensajes

**1. Configurar Sesi√≥n**
```javascript
ws.send(JSON.stringify({
  type: 'session.configure',
  language: 'maya',
  includesTramitesContext: true
}));
```

**2. Esperar Confirmaci√≥n**
```javascript
ws.on('message', (data) => {
  const message = JSON.parse(data);
  if (message.type === 'session.ready') {
    console.log('Sesi√≥n lista');
  }
});
```

**3. Enviar Audio**
```javascript
ws.send(JSON.stringify({
  type: 'input_audio_buffer.append',
  audio: base64AudioData
}));
```

**4. Recibir Respuestas**
Los eventos de OpenAI Realtime API se reenv√≠an directamente al cliente:
- `conversation.item.created`
- `response.audio.delta`
- `response.audio_transcript.delta`
- `response.done`

## üîß Integraci√≥n con Swift

### Ejemplo b√°sico en SwiftUI:

```swift
import Foundation

class MayaTranslatorService: ObservableObject {
    private var webSocket: URLSessionWebSocketTask?
    private let serverURL = "wss://your-app.vercel.app/realtime"
    
    @Published var isConnected = false
    @Published var currentTranscript = ""
    @Published var audioData: Data?
    
    func connect(language: String = "maya") {
        let url = URL(string: serverURL)!
        webSocket = URLSession.shared.webSocketTask(with: url)
        webSocket?.resume()
        
        // Configurar sesi√≥n
        let config = [
            "type": "session.configure",
            "language": language,
            "includesTramitesContext": true
        ]
        
        sendMessage(config)
        receiveMessages()
    }
    
    func sendAudio(_ audioData: Data) {
        let base64Audio = audioData.base64EncodedString()
        let message = [
            "type": "input_audio_buffer.append",
            "audio": base64Audio
        ]
        sendMessage(message)
    }
    
    private func sendMessage(_ dict: [String: Any]) {
        guard let data = try? JSONSerialization.data(withJSONObject: dict),
              let string = String(data: data, encoding: .utf8) else {
            return
        }
        
        let message = URLSessionWebSocketTask.Message.string(string)
        webSocket?.send(message) { error in
            if let error = error {
                print("Error sending: \(error)")
            }
        }
    }
    
    private func receiveMessages() {
        webSocket?.receive { [weak self] result in
            switch result {
            case .success(let message):
                switch message {
                case .string(let text):
                    self?.handleMessage(text)
                case .data(let data):
                    print("Received data: \(data)")
                @unknown default:
                    break
                }
                self?.receiveMessages()
                
            case .failure(let error):
                print("WebSocket error: \(error)")
            }
        }
    }
    
    private func handleMessage(_ text: String) {
        guard let data = text.data(using: .utf8),
              let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let type = json["type"] as? String else {
            return
        }
        
        switch type {
        case "session.ready":
            isConnected = true
            
        case "response.audio_transcript.delta":
            if let delta = json["delta"] as? String {
                currentTranscript += delta
            }
            
        case "response.audio.delta":
            if let audioBase64 = json["delta"] as? String,
               let audioData = Data(base64Encoded: audioBase64) {
                self.audioData = audioData
            }
            
        default:
            break
        }
    }
}
```

## üé® Vista Similar a Gemini Live

Para crear la interfaz como Gemini Live (imagen que compartiste):

```swift
struct LiveTranslatorView: View {
    @StateObject private var translator = MayaTranslatorService()
    @State private var isRecording = false
    
    var body: some View {
        ZStack {
            // Fondo con gradiente animado
            AnimatedGradientBackground()
            
            VStack {
                // Indicador de "Live"
                HStack {
                    Image(systemName: "waveform")
                        .symbolEffect(.variableColor)
                    Text("Live")
                        .font(.title2)
                        .bold()
                }
                .foregroundColor(.white)
                .padding(.top, 40)
                
                Spacer()
                
                // Visualizaci√≥n de onda de sonido
                WaveformView(isActive: isRecording)
                    .frame(height: 200)
                
                // Transcripci√≥n en tiempo real
                Text(translator.currentTranscript)
                    .font(.title3)
                    .foregroundColor(.white)
                    .multilineTextAlignment(.center)
                    .padding()
                
                Spacer()
                
                // Botones de control
                HStack(spacing: 40) {
                    Button(action: {}) {
                        Image(systemName: "video")
                            .font(.system(size: 28))
                            .foregroundColor(.white)
                    }
                    
                    Button(action: {}) {
                        Image(systemName: "arrow.up.doc")
                            .font(.system(size: 28))
                            .foregroundColor(.white)
                    }
                    
                    Button(action: {}) {
                        Image(systemName: "pause.fill")
                            .font(.system(size: 28))
                            .foregroundColor(.white)
                    }
                    
                    Button(action: {
                        // Finalizar
                    }) {
                        Image(systemName: "xmark")
                            .font(.system(size: 28))
                            .foregroundColor(.white)
                            .padding()
                            .background(Color.red)
                            .clipShape(Circle())
                    }
                }
                .padding(.bottom, 60)
            }
        }
        .onAppear {
            translator.connect(language: "maya")
        }
    }
}
```

## üí∞ Costos Estimados

OpenAI Realtime API pricing (gpt-4o-realtime):
- **Audio input**: $100 / 1M tokens (~$0.06/min)
- **Audio output**: $200 / 1M tokens (~$0.24/min)
- **Text input**: $5 / 1M tokens
- **Text output**: $20 / 1M tokens

**Estimaci√≥n para 1000 usuarios/mes** (5 min promedio cada uno):
- 5000 minutos de audio
- ~$300 USD/mes en audio
- + costos de texto (~$50)
- **Total: ~$350 USD/mes**

## üõ°Ô∏è Seguridad

- ‚úÖ Rate limiting por IP
- ‚úÖ Variables de entorno para API keys
- ‚úÖ CORS configurado
- ‚úÖ Validaci√≥n de inputs
- ‚ö†Ô∏è TODO: Agregar autenticaci√≥n JWT para producci√≥n

## üìù Licencia

MIT

## ü§ù Contribuir

Pull requests son bienvenidos. Para cambios mayores, por favor abre un issue primero.

## üìß Contacto

- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- Email: tu-email@example.com

---

**Desarrollado con ‚ù§Ô∏è para preservar las lenguas ind√≠genas de M√©xico**
